{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "f = open('page1.txt', 'r')\n",
    "# for line in f:\n",
    "    # print(line)\n",
    "\n",
    "# remove all characters that are not a-z, A-Z, 0-9, or space, ()[]{}.,;!?'\"-+= next line\n",
    "# remove empty lines\n",
    "with open('dress.txt', 'a') as f_C:\n",
    "\n",
    "    for line in f:\n",
    "        try:\n",
    "            line = re.sub(r'[^a-zA-Z0-9 \\n\\(\\)\\[\\]\\{\\}\\.\\,\\;\\!\\?\\'\\\"\\-\\+\\=]', '', line)\n",
    "            f_C.write(line)\n",
    "        except:\n",
    "            print(line)\n",
    "# write these lines to a new file\n",
    "# with open('story.txt', 'w') as f:\n",
    "#     f.write(line)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('products.csv')\n",
    "f = open('story.txt', 'r')\n",
    "instock = 1\n",
    "temp = 0\n",
    "for line in f:\n",
    "    if 'Get notified when this item comes back in stock.' in line:\n",
    "        instock = 0\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urllib.request.Request object at 0x000001ECA5A859F0>\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 500: Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [31]\u001B[0m, in \u001B[0;36m<cell line: 13>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     11\u001B[0m r \u001B[38;5;241m=\u001B[39m urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39mRequest(link, headers\u001B[38;5;241m=\u001B[39mheaders)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(r)\n\u001B[1;32m---> 13\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43murllib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m thePage \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m     16\u001B[0m soup \u001B[38;5;241m=\u001B[39m bs4\u001B[38;5;241m.\u001B[39mBeautifulSoup(thePage)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001B[0m, in \u001B[0;36murlopen\u001B[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    215\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[1;32m--> 216\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopener\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:525\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[1;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[0;32m    523\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m processor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_response\u001B[38;5;241m.\u001B[39mget(protocol, []):\n\u001B[0;32m    524\u001B[0m     meth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(processor, meth_name)\n\u001B[1;32m--> 525\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mmeth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:634\u001B[0m, in \u001B[0;36mHTTPErrorProcessor.http_response\u001B[1;34m(self, request, response)\u001B[0m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001B[39;00m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;66;03m# request was successfully received, understood, and accepted.\u001B[39;00m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m code \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m):\n\u001B[1;32m--> 634\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    635\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhttp\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhdrs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    637\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:563\u001B[0m, in \u001B[0;36mOpenerDirector.error\u001B[1;34m(self, proto, *args)\u001B[0m\n\u001B[0;32m    561\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_err:\n\u001B[0;32m    562\u001B[0m     args \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mdict\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp_error_default\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m+\u001B[39m orig_args\n\u001B[1;32m--> 563\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_chain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[1;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[0;32m    494\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m handler \u001B[38;5;129;01min\u001B[39;00m handlers:\n\u001B[0;32m    495\u001B[0m     func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[1;32m--> 496\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    497\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    498\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:643\u001B[0m, in \u001B[0;36mHTTPDefaultErrorHandler.http_error_default\u001B[1;34m(self, req, fp, code, msg, hdrs)\u001B[0m\n\u001B[0;32m    642\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhttp_error_default\u001B[39m(\u001B[38;5;28mself\u001B[39m, req, fp, code, msg, hdrs):\n\u001B[1;32m--> 643\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(req\u001B[38;5;241m.\u001B[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001B[1;31mHTTPError\u001B[0m: HTTP Error 500: Internal Server Error"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import bs4\n",
    "import re\n",
    "\n",
    "item=\"Wilco Classic Library: Autobiography Of a Yogi (Hardcover)\"\n",
    "item.replace(\" \", \"+\")\n",
    "link = 'http://www.flipkart.com/search/a/all?query={0}&vertical=all&dd=0&autosuggest[as]=off&autosuggest[as-submittype]=entered&autosuggest[as-grouprank]=0&autosuggest[as-overallrank]=0&autosuggest[orig-query]=&autosuggest[as-shown]=off&Search=%C2%A0&otracker=start&_r=YSWdYULYzr4VBYklfpZRbw--&_l=pMHn9vNCOBi05LKC_PwHFQ--&ref=a2c6fadc-2e24-4412-be6a-ce02c9707310&selmitem=All+Categories'.format(item)\n",
    "link = \"https://www.flipkart.com/devkiariz-women-printed-ethnic-dress-kurta/p/itm854849b9ed9a5\"  # Replace with your target URL\n",
    "headers = {\"User-Agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0'}\n",
    "\n",
    "r = urllib.request.Request(link, headers=headers)\n",
    "print(r)\n",
    "response = urllib.request.urlopen(r)\n",
    "\n",
    "thePage = response.read()\n",
    "soup = bs4.BeautifulSoup(thePage)\n",
    "print(soup.prettify())\n",
    "firstBlockSoup = soup.find('div', attrs={'class': 'fk-srch-item'})\n",
    "priceSoup=firstBlockSoup.find('b',attrs={'class':'fksd-bodytext price final-price'})\n",
    "price=priceSoup.contents[0]\n",
    "print(price)\n",
    "\n",
    "titleSoup=firstBlockSoup.find('a',attrs={'class':'fk-srch-title-text fksd-bodytext'})\n",
    "title=titleSoup.findAll('b')\n",
    "print(title[0].contents[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "  Downloading Scrapy-2.11.0-py2.py3-none-any.whl (286 kB)\n",
      "     -------------------------------------- 286.4/286.4 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting Twisted<23.8.0,>=18.9.0 (from scrapy)\n",
      "  Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)\n",
      "     ---------------------------------------- 3.1/3.1 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting cryptography>=36.0.0 (from scrapy)\n",
      "  Downloading cryptography-41.0.4-cp37-abi3-win_amd64.whl (2.7 MB)\n",
      "     ---------------------------------------- 2.7/2.7 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting cssselect>=0.9.1 (from scrapy)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting itemloaders>=1.0.1 (from scrapy)\n",
      "  Downloading itemloaders-1.1.0-py3-none-any.whl (11 kB)\n",
      "Collecting parsel>=1.5.0 (from scrapy)\n",
      "  Downloading parsel-1.8.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting pyOpenSSL>=21.0.0 (from scrapy)\n",
      "  Downloading pyOpenSSL-23.2.0-py3-none-any.whl (59 kB)\n",
      "     ---------------------------------------- 59.0/59.0 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting queuelib>=1.4.2 (from scrapy)\n",
      "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting service-identity>=18.1.0 (from scrapy)\n",
      "  Downloading service_identity-23.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting w3lib>=1.17.0 (from scrapy)\n",
      "  Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
      "Collecting zope.interface>=5.1.0 (from scrapy)\n",
      "  Downloading zope.interface-6.1-cp310-cp310-win_amd64.whl (204 kB)\n",
      "     -------------------------------------- 204.2/204.2 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting protego>=0.1.15 (from scrapy)\n",
      "  Downloading Protego-0.3.0-py2.py3-none-any.whl (8.5 kB)\n",
      "Collecting itemadapter>=0.1.0 (from scrapy)\n",
      "  Downloading itemadapter-0.8.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (67.6.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (21.3)\n",
      "Collecting tldextract (from scrapy)\n",
      "  Downloading tldextract-5.0.1-py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 97.1/97.1 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: lxml>=4.4.1 in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scrapy) (4.9.3)\n",
      "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
      "  Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography>=36.0.0->scrapy) (1.15.1)\n",
      "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (21.4.0)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
      "Collecting constantly>=15.1 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting incremental>=21.3.0 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Automat>=0.8.0 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting hyperlink>=17.1.1 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "     ---------------------------------------- 74.6/74.6 kB 4.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (4.3.0)\n",
      "Collecting twisted-iocpsupport<2,>=1.0.2 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Downloading twisted_iocpsupport-1.0.4-cp310-cp310-win_amd64.whl (46 kB)\n",
      "     ---------------------------------------- 46.8/46.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->scrapy) (3.0.8)\n",
      "Requirement already satisfied: idna in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tldextract->scrapy) (3.3)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tldextract->scrapy) (2.31.0)\n",
      "Collecting requests-file>=1.4 (from tldextract->scrapy)\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\vartika\\appdata\\roaming\\python\\python310\\site-packages (from tldextract->scrapy) (3.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Automat>=0.8.0->Twisted<23.8.0,>=18.9.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2022.6.15)\n",
      "Installing collected packages: twisted-iocpsupport, PyDispatcher, incremental, constantly, zope.interface, w3lib, queuelib, protego, jmespath, itemadapter, hyperlink, cssselect, Automat, Twisted, requests-file, parsel, cryptography, tldextract, service-identity, pyOpenSSL, itemloaders, scrapy\n",
      "Successfully installed Automat-22.10.0 PyDispatcher-2.0.7 Twisted-22.10.0 constantly-15.1.0 cryptography-41.0.4 cssselect-1.2.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.8.0 itemloaders-1.1.0 jmespath-1.0.1 parsel-1.8.1 protego-0.3.0 pyOpenSSL-23.2.0 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.11.0 service-identity-23.1.0 tldextract-5.0.1 twisted-iocpsupport-1.0.4 w3lib-2.1.2 zope.interface-6.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'amazon_scraper', using template directory 'C:\\Users\\Vartika\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\scrapy\\templates\\project', created in:\n",
      "    C:\\Users\\Vartika\\Documents\\GitHub\\Language-model\\amazon_scraper\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd amazon_scraper\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject amazon_scraper\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vartika\\Documents\\GitHub\\Language-model\\spidy.py already exists\n",
      "Created spider 'amazon' using template 'basic' \n"
     ]
    }
   ],
   "source": [
    "!scrapy genspider spidy website.com\n",
    "!scrapy genspider amazon amazon.com"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
