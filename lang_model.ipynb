{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90607e145671442baea81fff456eca85"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "(…)g-finetuned-squad/resolve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7cb0d3321eb946c9b7682cf07a361f01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(…)squad/resolve/main/tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc22f24489e842009f6052fa0adebc8f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "data = json.loads(open('product_details.json').read())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input <module 'json' from 'C:\\\\Users\\\\Vartika\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\json\\\\__init__.py'> is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [20]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m question \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhat is the name?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 2\u001B[0m input_ids \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(input_ids)\n\u001B[0;32m      4\u001B[0m attention_mask \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(input_ids)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2373\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.encode\u001B[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001B[0m\n\u001B[0;32m   2336\u001B[0m \u001B[38;5;129m@add_end_docstrings\u001B[39m(\n\u001B[0;32m   2337\u001B[0m     ENCODE_KWARGS_DOCSTRING,\n\u001B[0;32m   2338\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2356\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2357\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[\u001B[38;5;28mint\u001B[39m]:\n\u001B[0;32m   2358\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2359\u001B[0m \u001B[38;5;124;03m    Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.\u001B[39;00m\n\u001B[0;32m   2360\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2371\u001B[0m \u001B[38;5;124;03m            method).\u001B[39;00m\n\u001B[0;32m   2372\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2373\u001B[0m     encoded_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_plus(\n\u001B[0;32m   2374\u001B[0m         text,\n\u001B[0;32m   2375\u001B[0m         text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[0;32m   2376\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m   2377\u001B[0m         padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m   2378\u001B[0m         truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[0;32m   2379\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[0;32m   2380\u001B[0m         stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[0;32m   2381\u001B[0m         return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[0;32m   2382\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2383\u001B[0m     )\n\u001B[0;32m   2385\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m encoded_inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2781\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.encode_plus\u001B[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2771\u001B[0m \u001B[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001B[39;00m\n\u001B[0;32m   2772\u001B[0m padding_strategy, truncation_strategy, max_length, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_padding_truncation_strategies(\n\u001B[0;32m   2773\u001B[0m     padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m   2774\u001B[0m     truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2778\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2779\u001B[0m )\n\u001B[1;32m-> 2781\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_encode_plus(\n\u001B[0;32m   2782\u001B[0m     text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[0;32m   2783\u001B[0m     text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[0;32m   2784\u001B[0m     add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m   2785\u001B[0m     padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[0;32m   2786\u001B[0m     truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[0;32m   2787\u001B[0m     max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[0;32m   2788\u001B[0m     stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[0;32m   2789\u001B[0m     is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[0;32m   2790\u001B[0m     pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[0;32m   2791\u001B[0m     return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[0;32m   2792\u001B[0m     return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[0;32m   2793\u001B[0m     return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[0;32m   2794\u001B[0m     return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[0;32m   2795\u001B[0m     return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[0;32m   2796\u001B[0m     return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[0;32m   2797\u001B[0m     return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[0;32m   2798\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m   2799\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2800\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils.py:657\u001B[0m, in \u001B[0;36mPreTrainedTokenizer._encode_plus\u001B[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    648\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m    649\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    650\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    653\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://github.com/huggingface/transformers/pull/2674\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    654\u001B[0m     )\n\u001B[0;32m    656\u001B[0m first_ids \u001B[38;5;241m=\u001B[39m get_input_ids(text)\n\u001B[1;32m--> 657\u001B[0m second_ids \u001B[38;5;241m=\u001B[39m \u001B[43mget_input_ids\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    659\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_for_model(\n\u001B[0;32m    660\u001B[0m     first_ids,\n\u001B[0;32m    661\u001B[0m     pair_ids\u001B[38;5;241m=\u001B[39msecond_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    675\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m    676\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils.py:642\u001B[0m, in \u001B[0;36mPreTrainedTokenizer._encode_plus.<locals>.get_input_ids\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m    637\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    638\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtext\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not valid. Should be a string or a list/tuple of strings when\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    639\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m `is_split_into_words=True`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    640\u001B[0m     )\n\u001B[0;32m    641\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 642\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    643\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtext\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not valid. Should be a string, a list/tuple of strings or a list/tuple of\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    644\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m integers.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    645\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Input <module 'json' from 'C:\\\\Users\\\\Vartika\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\json\\\\__init__.py'> is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers."
     ]
    }
   ],
   "source": [
    "question = \"What is the name?\"\n",
    "input_ids = tokenizer.encode(question, json)\n",
    "print(input_ids)\n",
    "attention_mask = [1] * len(input_ids)\n",
    "output = model(torch.tensor([input_ids]), attention_mask=torch.tensor([attention_mask]))\n",
    "start_index = torch.argmax(output[0][0, :len(input_ids) - input_ids.index(tokenizer.sep_token_id)])\n",
    "end_index = torch.argmax(output[1][0, :len(input_ids) - input_ids.index(tokenizer.sep_token_id)])\n",
    "answer = tokenizer.decode(input_ids[start_index:end_index + 1], skip_special_tokens=True)\n",
    "print(\"Answer:\", answer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# convert json to a csv file\n",
    "import pandas as pd\n",
    "import json\n",
    "data = json.loads(open('product_details.json').read())\n",
    "\n",
    "brand = data['brand']\n",
    "description = data['description']\n",
    "highlights = data['highlights']\n",
    "image = data['image']\n",
    "name = data['name']\n",
    "price = data['price']\n",
    "product_description = data['product_description']\n",
    "rating = data['rating']\n",
    "review_count = data['review_count']\n",
    "specifications = data['specifications']\n",
    "\n",
    "# make a dataframe with columns as the keys of the json file\n",
    "df = pd.DataFrame(columns=['brand', 'description', 'highlights', 'image', 'name', 'price', 'product_description', 'rating', 'review_count', 'specifications'])\n",
    "df.loc[0] = [brand, description, highlights, image, name, price, product_description, rating, review_count, specifications]\n",
    "df.to_csv('product_details.csv', index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "   brand                                        description  \\\n0  APPLE  iPhone 13. boasts an advanced dual-camera syst...   \n\n                                          highlights  \\\n0  ['128 GB ROM', '15.49 cm (6.1 inch) Super Reti...   \n\n                                               image  \\\n0  http://rukmini1.flixcart.com/image/128/128/ktk...   \n\n                             name  price  \\\n0  APPLE iPhone 13 (Pink, 128 GB)  51999   \n\n                                 product_description  rating  review_count  \\\n0  ['A more vivid OLED display that’s both easier...     4.7         13141   \n\n                                      specifications  \n0  {'Battery & Power Features': {'Battery Capacit...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brand</th>\n      <th>description</th>\n      <th>highlights</th>\n      <th>image</th>\n      <th>name</th>\n      <th>price</th>\n      <th>product_description</th>\n      <th>rating</th>\n      <th>review_count</th>\n      <th>specifications</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>APPLE</td>\n      <td>iPhone 13. boasts an advanced dual-camera syst...</td>\n      <td>['128 GB ROM', '15.49 cm (6.1 inch) Super Reti...</td>\n      <td>http://rukmini1.flixcart.com/image/128/128/ktk...</td>\n      <td>APPLE iPhone 13 (Pink, 128 GB)</td>\n      <td>51999</td>\n      <td>['A more vivid OLED display that’s both easier...</td>\n      <td>4.7</td>\n      <td>13141</td>\n      <td>{'Battery &amp; Power Features': {'Battery Capacit...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('product_details.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
